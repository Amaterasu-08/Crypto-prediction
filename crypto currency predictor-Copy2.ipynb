{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto Predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"crypto_data/LTC-USD.csv\",names = ['time','low','high', 'open','close','volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1528968660</td>\n",
       "      <td>96.580002</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>96.580002</td>\n",
       "      <td>9.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1528968720</td>\n",
       "      <td>96.449997</td>\n",
       "      <td>96.669998</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>96.660004</td>\n",
       "      <td>314.387024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1528968780</td>\n",
       "      <td>96.470001</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>77.129799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1528968840</td>\n",
       "      <td>96.449997</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>7.216067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1528968900</td>\n",
       "      <td>96.279999</td>\n",
       "      <td>96.540001</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>96.389999</td>\n",
       "      <td>524.539978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time        low       high       open      close      volume\n",
       "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
       "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
       "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
       "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n",
       "4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = ['BTC-USD','LTC-USD','ETH-USD','BCH-USD']\n",
    "\n",
    "for ratio in ratios:\n",
    "    dataset = f\"crypto_data/{ratio}.csv\"\n",
    "    \n",
    "    df = pd.read_csv(dataset, names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volume\"])\n",
    "    df.rename(columns={\"close\" : f\"{ratio}_close\",\"volume\":f\"{ratio}_volume\"},inplace=True)\n",
    "    \n",
    "    df.set_index(\"time\",inplace=True)\n",
    "    df = df[[f\"{ratio}_close\",f\"{ratio}_volume\"]]\n",
    "    \n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_close</th>\n",
       "      <th>BTC-USD_volume</th>\n",
       "      <th>LTC-USD_close</th>\n",
       "      <th>LTC-USD_volume</th>\n",
       "      <th>ETH-USD_close</th>\n",
       "      <th>ETH-USD_volume</th>\n",
       "      <th>BCH-USD_close</th>\n",
       "      <th>BCH-USD_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528968660</th>\n",
       "      <td>6489.549805</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>96.580002</td>\n",
       "      <td>9.647200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>871.719971</td>\n",
       "      <td>5.675361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968720</th>\n",
       "      <td>6487.379883</td>\n",
       "      <td>7.706374</td>\n",
       "      <td>96.660004</td>\n",
       "      <td>314.387024</td>\n",
       "      <td>486.010010</td>\n",
       "      <td>26.019083</td>\n",
       "      <td>870.859985</td>\n",
       "      <td>26.856577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968780</th>\n",
       "      <td>6479.410156</td>\n",
       "      <td>3.088252</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>77.129799</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>8.449400</td>\n",
       "      <td>870.099976</td>\n",
       "      <td>1.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968840</th>\n",
       "      <td>6479.410156</td>\n",
       "      <td>1.404100</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>7.216067</td>\n",
       "      <td>485.750000</td>\n",
       "      <td>26.994646</td>\n",
       "      <td>870.789978</td>\n",
       "      <td>1.749862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968900</th>\n",
       "      <td>6479.979980</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>96.389999</td>\n",
       "      <td>524.539978</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>77.355759</td>\n",
       "      <td>870.000000</td>\n",
       "      <td>1.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214960</th>\n",
       "      <td>6713.140137</td>\n",
       "      <td>0.769891</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>6.434783</td>\n",
       "      <td>279.359985</td>\n",
       "      <td>11.280577</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>1.208560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215020</th>\n",
       "      <td>6714.520020</td>\n",
       "      <td>1.002652</td>\n",
       "      <td>58.009998</td>\n",
       "      <td>7.301921</td>\n",
       "      <td>279.359985</td>\n",
       "      <td>8.790519</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.016868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215080</th>\n",
       "      <td>6714.520020</td>\n",
       "      <td>1.021925</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>23.802017</td>\n",
       "      <td>279.369995</td>\n",
       "      <td>1.311763</td>\n",
       "      <td>531.469971</td>\n",
       "      <td>0.013854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215140</th>\n",
       "      <td>6715.000000</td>\n",
       "      <td>3.645508</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>6.953497</td>\n",
       "      <td>279.660004</td>\n",
       "      <td>11.752819</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215200</th>\n",
       "      <td>6715.000000</td>\n",
       "      <td>0.513560</td>\n",
       "      <td>58.080002</td>\n",
       "      <td>202.403183</td>\n",
       "      <td>279.649994</td>\n",
       "      <td>8.351710</td>\n",
       "      <td>531.479980</td>\n",
       "      <td>0.299520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97724 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
       "time                                                                       \n",
       "1528968660    6489.549805        0.587100      96.580002        9.647200   \n",
       "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
       "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
       "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
       "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
       "...                   ...             ...            ...             ...   \n",
       "1535214960    6713.140137        0.769891      58.020000        6.434783   \n",
       "1535215020    6714.520020        1.002652      58.009998        7.301921   \n",
       "1535215080    6714.520020        1.021925      58.020000       23.802017   \n",
       "1535215140    6715.000000        3.645508      58.020000        6.953497   \n",
       "1535215200    6715.000000        0.513560      58.080002      202.403183   \n",
       "\n",
       "            ETH-USD_close  ETH-USD_volume  BCH-USD_close  BCH-USD_volume  \n",
       "time                                                                      \n",
       "1528968660            NaN             NaN     871.719971        5.675361  \n",
       "1528968720     486.010010       26.019083     870.859985       26.856577  \n",
       "1528968780     486.000000        8.449400     870.099976        1.124300  \n",
       "1528968840     485.750000       26.994646     870.789978        1.749862  \n",
       "1528968900     486.000000       77.355759     870.000000        1.680500  \n",
       "...                   ...             ...            ...             ...  \n",
       "1535214960     279.359985       11.280577     531.479980        1.208560  \n",
       "1535215020     279.359985        8.790519     531.479980        0.016868  \n",
       "1535215080     279.369995        1.311763     531.469971        0.013854  \n",
       "1535215140     279.660004       11.752819     531.479980        0.016900  \n",
       "1535215200     279.649994        8.351710     531.479980        0.299520  \n",
       "\n",
       "[97724 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60 #WE HAVE THE DATA OF PREVIOUS 60 MIN\n",
    "FUTURE_PERIOD_PREDICT = 3 # TRY TO PREDICT 3 MIN IN THE FUTURE\n",
    "RATIO_TO_PREDICT = \"LTC-USD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(present, future):\n",
    "    if float(future) >= float(present):\n",
    "        return 1      # it implies the crypto yeilds profit\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['future'] = main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT) # shift the row or column depend on axis specification by a certain number secified in the shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "1528968660    96.500000\n",
       "1528968720    96.389999\n",
       "1528968780    96.519997\n",
       "1528968840    96.440002\n",
       "1528968900    96.470001\n",
       "Name: future, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['future'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LTC-USD_close</th>\n",
       "      <th>future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528968660</th>\n",
       "      <td>96.580002</td>\n",
       "      <td>96.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968720</th>\n",
       "      <td>96.660004</td>\n",
       "      <td>96.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968780</th>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968840</th>\n",
       "      <td>96.500000</td>\n",
       "      <td>96.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968900</th>\n",
       "      <td>96.389999</td>\n",
       "      <td>96.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214960</th>\n",
       "      <td>58.020000</td>\n",
       "      <td>58.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215020</th>\n",
       "      <td>58.009998</td>\n",
       "      <td>58.080002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215080</th>\n",
       "      <td>58.020000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215140</th>\n",
       "      <td>58.020000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215200</th>\n",
       "      <td>58.080002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LTC-USD_close     future\n",
       "time                                \n",
       "1528968660      96.580002  96.500000\n",
       "1528968720      96.660004  96.389999\n",
       "1528968780      96.570000  96.519997\n",
       "1528968840      96.500000  96.440002\n",
       "1528968900      96.389999  96.470001\n",
       "...                   ...        ...\n",
       "1535214960      58.020000  58.020000\n",
       "1535215020      58.009998  58.080002\n",
       "1535215080      58.020000        NaN\n",
       "1535215140      58.020000        NaN\n",
       "1535215200      58.080002        NaN\n",
       "\n",
       "[97724 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create target variable\n",
    "\n",
    "main_df['target'] = list(map(classify, main_df[f\"{RATIO_TO_PREDICT}_close\"], main_df['future'])) #map current and future as typed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LTC-USD_close</th>\n",
       "      <th>future</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528968660</th>\n",
       "      <td>96.580002</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968720</th>\n",
       "      <td>96.660004</td>\n",
       "      <td>96.389999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968780</th>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.519997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968840</th>\n",
       "      <td>96.500000</td>\n",
       "      <td>96.440002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528968900</th>\n",
       "      <td>96.389999</td>\n",
       "      <td>96.470001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535214960</th>\n",
       "      <td>58.020000</td>\n",
       "      <td>58.020000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215020</th>\n",
       "      <td>58.009998</td>\n",
       "      <td>58.080002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215080</th>\n",
       "      <td>58.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215140</th>\n",
       "      <td>58.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535215200</th>\n",
       "      <td>58.080002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97724 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LTC-USD_close     future  target\n",
       "time                                        \n",
       "1528968660      96.580002  96.500000       0\n",
       "1528968720      96.660004  96.389999       0\n",
       "1528968780      96.570000  96.519997       0\n",
       "1528968840      96.500000  96.440002       0\n",
       "1528968900      96.389999  96.470001       1\n",
       "...                   ...        ...     ...\n",
       "1535214960      58.020000  58.020000       1\n",
       "1535215020      58.009998  58.080002       1\n",
       "1535215080      58.020000        NaN       0\n",
       "1535215140      58.020000        NaN       0\n",
       "1535215200      58.080002        NaN       0\n",
       "\n",
       "[97724 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534922100\n"
     ]
    }
   ],
   "source": [
    "times = sorted(main_df.index.values) #values convert it to numpy array\n",
    "\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "print(last_5pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating data into validation and test\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "\n",
    "main_df = main_df[(main_df.index < last_5pct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functon to perform preprocessing\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future',1)\n",
    "    \n",
    "    #iterate over the column and scale the column\n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            df[col] = df[col].pct_change() #pct_change normalises the data\n",
    "            df.dropna(inplace = True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "            \n",
    "    df.dropna(inplace = True)\n",
    "    \n",
    "    sequential_data = []\n",
    "    previous_days = deque(maxlen = SEQ_LEN) #previous_day is a list as soon the list reaches maxlen value it gets new items it pops the old items\n",
    "    \n",
    "    # to check the result of the function \n",
    "    # print(df.head())\n",
    "    for i in df.values: # df.values convert ur datafraame to a list of list(here it is list of column) it wont contain time but it is in order but it will contain target\n",
    "        previous_days.append([n for n in i[:-1]]) #we need to append a list, n for n is each value in that list of list(n=> each row element), -1 mean excluding the target column \n",
    "        if len(previous_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(previous_days), i[-1]]) #now append x and y i.e features and label\n",
    "        \n",
    "        \n",
    "        \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    # balance the data => buys = sells \n",
    "    buys = []\n",
    "    sells = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target ==0: #i.e sell\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "            \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    #know which is lower buys or sells\n",
    "    lower = min(len(buys), len(sells))\n",
    "    \n",
    "    #to equalise the buys and sells\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "    \n",
    "    sequential_data = buys + sells\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    # now to seperate the features and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        \n",
    "    return np.array(X), y\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 1.98993787e-02, -6.53351351e-02, -7.41317091e-02, ...,\n",
       "          -5.05482196e-02, -4.98993163e-03, -6.21331166e-03],\n",
       "         [-8.30083053e-04, -6.15952077e-02,  8.22366276e-02, ...,\n",
       "          -2.43234320e-02,  2.45620675e-01, -4.20153788e-03],\n",
       "         [-8.30083053e-04, -6.39032399e-02,  5.51199623e-01, ...,\n",
       "          -1.01321610e-02,  6.33477705e-01, -6.03986839e-03],\n",
       "         ...,\n",
       "         [ 8.45221872e-02, -5.20355903e-02,  8.22392505e-02, ...,\n",
       "          -3.64955975e-02, -4.14424361e-01, -6.22434609e-03],\n",
       "         [ 3.49053805e-01, -6.18255235e-02,  4.04838613e-03, ...,\n",
       "          -4.41869565e-02,  1.13020993e-02, -4.76295985e-03],\n",
       "         [-8.30083053e-04, -4.43714927e-02,  4.04838613e-03, ...,\n",
       "          -5.03254856e-02,  3.10232629e-03, -5.63677635e-03]],\n",
       " \n",
       "        [[ 1.74157749e+00,  3.83218620e-01,  1.84184342e-01, ...,\n",
       "          -3.40659878e-02,  1.53908600e+00, -6.17728386e-03],\n",
       "         [ 4.60459077e-01, -8.38470254e-02,  4.04838613e-03, ...,\n",
       "          -5.07247846e-02, -1.68188414e+00, -6.18306502e-03],\n",
       "         [-1.36902782e+00, -2.61438782e-02, -7.16448588e-01, ...,\n",
       "           4.22207701e-02, -8.54192736e-01, -6.18877507e-03],\n",
       "         ...,\n",
       "         [-2.26904582e-02, -5.29121268e-02,  9.40830437e-02, ...,\n",
       "          -3.92136874e-02, -2.77036261e-01, -6.20181878e-03],\n",
       "         [-1.09960379e+00, -6.21534569e-02,  4.04838613e-03, ...,\n",
       "          -3.82026163e-02, -4.04499076e-01, -6.16596063e-03],\n",
       "         [-8.24688070e-01, -8.18711735e-02,  4.04838613e-03, ...,\n",
       "          -4.72183315e-02,  6.40381550e-01, -3.59346422e-03]],\n",
       " \n",
       "        [[ 1.11224992e-03, -7.20705525e-02,  4.04838613e-03, ...,\n",
       "          -4.64537458e-02,  1.19039003e+00, -6.17088741e-03],\n",
       "         [-8.30083053e-04, -5.61478614e-02,  9.78546868e-01, ...,\n",
       "          -2.37655399e-02, -6.59874693e-01, -6.19427372e-03],\n",
       "         [ 1.12811556e+00, -5.38024168e-02,  9.77292685e-01, ...,\n",
       "          -4.78571386e-02, -1.11290153e+00, -6.10569342e-03],\n",
       "         ...,\n",
       "         [-6.35645622e-01, -6.82983489e-02,  4.04838613e-03, ...,\n",
       "          -3.47302315e-02,  2.33462199e-02, -6.22361893e-03],\n",
       "         [-2.00535102e+00,  7.95781689e-01, -2.72494668e+00, ...,\n",
       "          -4.30563542e-02, -2.69672310e+00,  1.18991037e-03],\n",
       "         [ 5.40320258e-01, -8.72035293e-02,  2.35171392e+00, ...,\n",
       "          -3.68519477e-02,  1.42428863e+00, -6.20265457e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.14887554e-02, -6.74455257e-02,  1.28258442e-01, ...,\n",
       "           5.10146853e-02, -1.76274775e+00, -6.04378726e-03],\n",
       "         [ 1.70162996e+00,  1.18380483e-02,  9.97787963e-01, ...,\n",
       "          -5.05188318e-02,  9.18424769e-01, -6.01221534e-03],\n",
       "         [ 2.24730044e-01, -5.26150747e-02,  4.04838613e-03, ...,\n",
       "          -4.62146092e-02, -8.93615783e-03, -6.19658079e-03],\n",
       "         ...,\n",
       "         [-7.31272349e-01,  6.84094274e-02,  4.04838613e-03, ...,\n",
       "          -4.54181341e-02, -5.63245979e-01, -6.21919235e-03],\n",
       "         [ 9.80209346e-04, -8.65168934e-02,  1.37952623e+00, ...,\n",
       "          -2.15142352e-02, -2.10417517e-02, -5.67987174e-03],\n",
       "         [-8.30083053e-04, -7.70859850e-02, -4.95168229e-01, ...,\n",
       "          -4.45546028e-02,  3.10232629e-03, -6.21401366e-03]],\n",
       " \n",
       "        [[ 1.45774515e+00, -4.89117442e-02,  9.74213764e-01, ...,\n",
       "          -5.04727752e-02,  2.31337228e-01, -5.78247342e-03],\n",
       "         [ 8.14450953e-04, -8.20968639e-02,  9.20873146e-02, ...,\n",
       "          -2.24965110e-02,  4.59421578e-01, -5.51651894e-03],\n",
       "         [ 8.39493225e-01, -6.41933035e-02,  1.85363541e+00, ...,\n",
       "          -6.52486474e-03,  1.22318155e-02, -6.19534517e-03],\n",
       "         ...,\n",
       "         [ 6.13069829e-01, -7.23229972e-02,  1.15811206e+00, ...,\n",
       "          -4.93444257e-02,  4.10316755e-01, -6.22195567e-03],\n",
       "         [-1.26691137e+00, -8.28232441e-02, -2.74367109e+00, ...,\n",
       "           4.72913733e-02, -4.31592022e-01, -6.19661014e-03],\n",
       "         [-8.54415042e-02, -5.90869999e-02, -7.96557370e-01, ...,\n",
       "          -4.95765461e-02,  1.08594527e+00, -6.13438798e-03]],\n",
       " \n",
       "        [[-1.08392961e+00, -7.90336614e-02,  4.04838613e-03, ...,\n",
       "          -5.06357563e-02, -5.35265076e-03, -6.05241191e-03],\n",
       "         [-8.30083053e-04, -7.53262833e-02,  4.04838613e-03, ...,\n",
       "          -7.52865856e-03,  3.10232629e-03, -6.21637023e-03],\n",
       "         [-2.22839937e-03, -7.52686940e-02,  6.30184032e-01, ...,\n",
       "          -2.97448959e-02,  1.15574067e-02,  1.33111897e-02],\n",
       "         ...,\n",
       "         [-2.16430128e-03, -6.77604472e-02,  9.37494657e-02, ...,\n",
       "          -5.00140283e-02, -5.37604662e-03,  5.73661006e-03],\n",
       "         [-8.30083053e-04, -7.38011304e-02, -8.56419717e-02, ...,\n",
       "          -4.06102159e-02,  1.97948057e-01, -6.18031897e-03],\n",
       "         [-7.39959449e-01,  5.67319339e-01,  9.37494657e-02, ...,\n",
       "           4.37929288e-02, -1.19086114e+00, -5.89561454e-03]]]),\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  ...])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_df(main_df) #things got converted to percent change and normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x , train_y = preprocess_df(main_df)\n",
    "validation_x , validation_y = preprocess_df(validation_main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting it to array\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "validation_x = np.asarray(validation_x)\n",
    "validation_y = np.asarray(validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 71236 ,validation: 3072\n",
      "Dont buys: 35618, Buys: 35618\n",
      "Validation Dont buy: 1536, Validation buys: 1536\n"
     ]
    }
   ],
   "source": [
    "print(f\"train data: {len(train_x)} ,validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {np.count_nonzero(train_y == 0)}, Buys: {np.count_nonzero(train_y == 1)}\")  #np.ndarray doesnt have the count function so we use array.count_nonzero() and can count the number of unique object in it by passing th value in the parenthesis \n",
    "print(f\"Validation Dont buy: {np.count_nonzero(validation_y == 0)}, Validation buys: {np.count_nonzero(validation_y == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization #BatchNormalization is normalisation between layers \n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint #ModelCheckpoint is  way to set parameters to when u want to save checkpoint ex like after 100 epochs so we track the model even before it breaks\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114/1114 [==============================] - ETA: 0s - loss: 0.7193 - accuracy: 0.5122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\RNN_Final-01-0.500.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\RNN_Final-01-0.500.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1114/1114 [==============================] - 297s 261ms/step - loss: 0.7193 - accuracy: 0.5122 - val_loss: 0.6940 - val_accuracy: 0.5003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: assets\n"
     ]
    }
   ],
   "source": [
    "model  = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\")) #binary choise 2 2 dense layer enough\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001, decay = 1e-6)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer = opt,\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = f'logs/{NAME}')\n",
    "\n",
    "filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\" #unique file name that will include the epoch and validation accuracy for that epoch\n",
    "checkpoint = ModelCheckpoint(\"model/{}.model\".format(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')) #save only the best one\n",
    "\n",
    "model.fit(train_x, train_y,\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   validation_data=(validation_x, validation_y),\n",
    "                   callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "model.save(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 5s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_x = model.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44852006 0.5514799 ]\n",
      " [0.5188537  0.48114628]\n",
      " [0.5189359  0.48106408]\n",
      " ...\n",
      " [0.5187816  0.48121837]\n",
      " [0.4728357  0.52716434]\n",
      " [0.477568   0.5224321 ]]\n",
      "(3072, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.44852006, 0.5514799 ], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predicted_x)\n",
    "print(predicted_x.shape)\n",
    "predicted_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 5s 38ms/step - loss: 0.6940 - accuracy: 0.5003\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(validation_x, validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6940186619758606 0.5003255009651184\n"
     ]
    }
   ],
   "source": [
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
